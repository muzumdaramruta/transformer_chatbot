{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8f4d8b1-ea5b-437c-890e-4a2b2f53ef8f",
   "metadata": {},
   "source": [
    "# Transformer Based Model for Chat-Bot\n",
    "Using Pytorch\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bb39cfa-baab-4126-97a5-1b874ad1fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b17eecd-c828-44f5-94c0-49e4a963ccf8",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fb879d7-e8af-4fce-9efc-64e25aed456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb469f5-8c11-4480-9c63-00a7677dc086",
   "metadata": {},
   "source": [
    "### Set Huperparameters for model\n",
    "\n",
    "- MAX_LEN = 40: The maximum length of input/output sequences (in tokens) for the model.\n",
    "- BATCH_SIZE = 64: The number of training samples processed in one forward/backward pass.\n",
    "- NUM_HEADS = 8: The number of attention heads in the multi-head attention mechanism.\n",
    "- D_MODEL = 512: The dimensionality of the model’s hidden layer representations.\n",
    "- FFN_UNITS = 2048: The number of units in the feed-forward neural network after each attention layer.\n",
    "- DROPOUT = 0.1: The fraction of units to drop during training to prevent overfitting.\n",
    "- NUM_LAYERS = 4: The number of layers in the encoder and decoder of the Transformer.\n",
    "- EPOCHS = 300: The number of full passes through the training dataset during training.\n",
    "- VOCAB_SIZE = 8000: The number of unique tokens in the model's vocabulary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ec4fa34-6cd2-4b58-9010-b4e896e5bd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "MAX_LEN = 40\n",
    "BATCH_SIZE = 64\n",
    "NUM_HEADS = 8\n",
    "D_MODEL = 512\n",
    "FFN_UNITS = 2048\n",
    "DROPOUT = 0.1\n",
    "NUM_LAYERS = 4\n",
    "EPOCHS = 300\n",
    "VOCAB_SIZE = 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c119b9-6cb3-4d47-b7a3-e2483232fdf5",
   "metadata": {},
   "source": [
    "#### Setup decide for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f3ff5a6-c9cc-4305-8df8-5ce528c35eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932ff2fe-40d5-4693-be1f-9f789d3120c8",
   "metadata": {},
   "source": [
    "#### load CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1aa6be1-6ad9-4829-a741-d1f87ed3a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/reminiscences_of_a_stock_operator_qa.csv'\n",
    "data = pd.read_csv(file_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74b1d25e-3a0c-42d0-be21-024dc61125ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = data['question'].tolist()\n",
    "answers = data['answer'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61822ca-dee0-4cfe-b078-261e5bb22143",
   "metadata": {},
   "source": [
    "### Custom Tokenizer to keepp track of vocab and word to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9ebb63f-e9df-47df-b438-c25a72969c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenizer:\n",
    "    def __init__(self, vocab_size):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.word2idx = {\"<pad>\": 0, \"<start>\": 1, \"<end>\": 2, \"<unk>\": 3}\n",
    "        self.idx2word = {0: \"<pad>\", 1: \"<start>\", 2: \"<end>\", 3: \"<unk>\"}\n",
    "        self.word_count = {}\n",
    "\n",
    "    def fit_on_texts(self, texts):\n",
    "        for text in texts:\n",
    "            for word in text.split():\n",
    "                self.word_count[word] = self.word_count.get(word, 0) + 1\n",
    "        sorted_vocab = sorted(self.word_count.items(), key=lambda x: x[1], reverse=True)[:self.vocab_size - 4]\n",
    "        for idx, (word, _) in enumerate(sorted_vocab, start=4):\n",
    "            self.word2idx[word] = idx\n",
    "            self.idx2word[idx] = word\n",
    "\n",
    "    def texts_to_sequences(self, texts):\n",
    "        sequences = []\n",
    "        for text in texts:\n",
    "            seq = [self.word2idx.get(word, self.word2idx[\"<unk>\"]) for word in text.split()]\n",
    "            sequences.append(seq)\n",
    "        return sequences\n",
    "\n",
    "    def sequences_to_texts(self, sequences):\n",
    "        texts = []\n",
    "        for seq in sequences:\n",
    "            text = \" \".join([self.idx2word.get(idx, \"<unk>\") for idx in seq])\n",
    "            texts.append(text)\n",
    "        return texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af66fe89-0ec2-4986-8c24-18b4ed6218a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CustomTokenizer(VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(questions + answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcb298b-77b0-4a5a-a305-2b0c701bdc65",
   "metadata": {},
   "source": [
    "### Initialize the dataset by converting the questions and answers to sequences of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19561f17-b729-4d70-b4d4-331871c1bff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatDataset(Dataset):\n",
    "    def __init__(self, questions, answers, tokenizer, max_len):\n",
    "        self.questions = tokenizer.texts_to_sequences(questions)\n",
    "        self.answers = tokenizer.texts_to_sequences(answers)\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question = self.questions[idx]\n",
    "        answer = self.answers[idx]\n",
    "\n",
    "        question = [1] + question[:self.max_len - 2] + [2]\n",
    "        answer = [1] + answer[:self.max_len - 2] + [2]\n",
    "\n",
    "        question = question + [0] * (self.max_len - len(question))\n",
    "        answer = answer + [0] * (self.max_len - len(answer))\n",
    "\n",
    "        return torch.tensor(question), torch.tensor(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed96643-bc40-433e-a615-37fb540bef3d",
   "metadata": {},
   "source": [
    "### Compute the scaled dot-product attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6a51001-bcdc-4a28-bb1d-bc09d0bfc215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = torch.matmul(q, k.transpose(-2, -1))\n",
    "    dk = q.size(-1)\n",
    "    scaled_attention_logits = matmul_qk / torch.sqrt(torch.tensor(dk, dtype=torch.float32, device=q.device))\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "    attention_weights = F.softmax(scaled_attention_logits, dim=-1)\n",
    "    output = torch.matmul(attention_weights, v)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5225062-e356-4a63-8bb7-ef9e7165c2a1",
   "metadata": {},
   "source": [
    "### Multi Head Atention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7004b140-c5f0-41e4-928f-cd912c579826",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        self.wq = nn.Linear(d_model, d_model)\n",
    "        self.wk = nn.Linear(d_model, d_model)\n",
    "        self.wv = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        batch_size = q.size(0)\n",
    "        q = self.wq(q).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
    "        k = self.wk(k).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
    "        v = self.wv(v).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
    "\n",
    "        attention = scaled_dot_product_attention(q, k, v, mask)\n",
    "        attention = attention.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        return self.dense(attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb8dbfe-e06a-4af2-9858-339a50bdc8da",
   "metadata": {},
   "source": [
    "### Initialize the feed-forward network with two linear layers, ReLU activation, and dropout regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9b3a10c-87c5-4d09-882c-8b8f35939c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, d_model, ffn_units, dropout_rate):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, ffn_units)\n",
    "        self.linear2 = nn.Linear(ffn_units, d_model)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.linear2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02458d2e-c74a-4c68-b617-9086758ca83a",
   "metadata": {},
   "source": [
    "### Encoder: Multi Head Attention with Layer normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ee82e1c-6f35-4f64-a1a2-b1c6f5a5afa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, ffn_units, dropout_rate):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = FeedForwardNetwork(d_model, ffn_units, dropout_rate)\n",
    "        self.layernorm1 = nn.LayerNorm(d_model)\n",
    "        self.layernorm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.attention(x, x, x, mask)\n",
    "        out1 = self.layernorm1(x + self.dropout(attn_output))\n",
    "        ffn_output = self.ffn(out1)\n",
    "        return self.layernorm2(out1 + self.dropout(ffn_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d2ec75-07ba-4a25-84a6-3188e4a0ded0",
   "metadata": {},
   "source": [
    "### Decoder: With look ahead mask and Cross attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4da4bee1-bfa6-42f0-8cda-27eef2fbca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, ffn_units, dropout_rate):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.attention1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.attention2 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = FeedForwardNetwork(d_model, ffn_units, dropout_rate)\n",
    "        self.layernorm1 = nn.LayerNorm(d_model)\n",
    "        self.layernorm2 = nn.LayerNorm(d_model)\n",
    "        self.layernorm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        attn1 = self.attention1(x, x, x, look_ahead_mask)\n",
    "        out1 = self.layernorm1(x + self.dropout(attn1))\n",
    "\n",
    "        attn2 = self.attention2(out1, enc_output, enc_output, padding_mask)\n",
    "        out2 = self.layernorm2(out1 + self.dropout(attn2))\n",
    "\n",
    "        ffn_output = self.ffn(out2)\n",
    "        return self.layernorm3(out2 + self.dropout(ffn_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8c687f9-584b-452c-ac24-8e18d0df7848",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.encoding = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        self.encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.encoding = self.encoding.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.encoding[:, :x.size(1), :].to(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c916da2-e8c9-49db-a6f8-4ffea81973cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_heads, ffn_units, num_layers, dropout_rate, max_len):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_len)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, ffn_units, dropout_rate)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, ffn_units, dropout_rate)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def create_look_ahead_mask(self, size):\n",
    "        mask = torch.triu(torch.ones(size, size), diagonal=1)\n",
    "        return mask == 1\n",
    "\n",
    "    def forward(self, encoder_input, decoder_input, encoder_mask=None, decoder_mask=None):\n",
    "        # Encoder\n",
    "        encoder_embedded = self.embedding(encoder_input)\n",
    "        encoder_embedded = self.positional_encoding(encoder_embedded)\n",
    "\n",
    "        encoder_output = encoder_embedded\n",
    "        for layer in self.encoder_layers:\n",
    "            encoder_output = layer(encoder_output, encoder_mask)\n",
    "\n",
    "        # Decoder\n",
    "        decoder_embedded = self.embedding(decoder_input)\n",
    "        decoder_embedded = self.positional_encoding(decoder_embedded)\n",
    "\n",
    "        look_ahead_mask = self.create_look_ahead_mask(decoder_input.size(1)).to(decoder_input.device)\n",
    "\n",
    "        decoder_output = decoder_embedded\n",
    "        for layer in self.decoder_layers:\n",
    "            decoder_output = layer(decoder_output, encoder_output, look_ahead_mask, encoder_mask)\n",
    "\n",
    "        return self.fc(decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a660e21b-fe89-4415-909d-e46a8bf51b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(VOCAB_SIZE, D_MODEL, NUM_HEADS, FFN_UNITS, NUM_LAYERS, DROPOUT, MAX_LEN)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e824dc40-c911-415e-8666-83dbc4195bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChatDataset(questions, answers, tokenizer, MAX_LEN)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8da8b2-9adb-4a14-b7b8-296f0b4c87aa",
   "metadata": {},
   "source": [
    "### Optimizer and loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d70f6833-b434-4da7-bcda-47a6245c75f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f9ab5a-8f26-422e-8f5c-60d89e46af4e",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "177bc4f8-7e3c-4df0-9bcd-efff2ebf7fb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300, Loss: 5.5032, Accuracy: 0.3662\n",
      "Epoch 2/300, Loss: 4.4478, Accuracy: 0.4203\n",
      "Epoch 3/300, Loss: 3.9433, Accuracy: 0.4389\n",
      "Epoch 4/300, Loss: 3.7801, Accuracy: 0.4529\n",
      "Epoch 5/300, Loss: 3.6486, Accuracy: 0.4767\n",
      "Epoch 6/300, Loss: 3.5726, Accuracy: 0.5061\n",
      "Epoch 7/300, Loss: 3.3048, Accuracy: 0.5241\n",
      "Epoch 8/300, Loss: 3.1798, Accuracy: 0.5382\n",
      "Epoch 9/300, Loss: 2.9465, Accuracy: 0.5491\n",
      "Epoch 10/300, Loss: 2.8544, Accuracy: 0.5615\n",
      "Epoch 11/300, Loss: 2.7124, Accuracy: 0.5695\n",
      "Epoch 12/300, Loss: 2.6106, Accuracy: 0.5807\n",
      "Epoch 13/300, Loss: 2.5330, Accuracy: 0.5869\n",
      "Epoch 14/300, Loss: 2.3795, Accuracy: 0.5963\n",
      "Epoch 15/300, Loss: 2.3047, Accuracy: 0.6050\n",
      "Epoch 16/300, Loss: 2.3672, Accuracy: 0.6138\n",
      "Epoch 17/300, Loss: 2.2210, Accuracy: 0.6189\n",
      "Epoch 18/300, Loss: 2.2178, Accuracy: 0.6257\n",
      "Epoch 19/300, Loss: 2.0740, Accuracy: 0.6372\n",
      "Epoch 20/300, Loss: 2.0231, Accuracy: 0.6464\n",
      "Epoch 21/300, Loss: 1.9146, Accuracy: 0.6536\n",
      "Epoch 22/300, Loss: 1.8078, Accuracy: 0.6640\n",
      "Epoch 23/300, Loss: 1.8287, Accuracy: 0.6731\n",
      "Epoch 24/300, Loss: 1.7625, Accuracy: 0.6786\n",
      "Epoch 25/300, Loss: 1.6305, Accuracy: 0.6905\n",
      "Epoch 26/300, Loss: 1.5784, Accuracy: 0.7003\n",
      "Epoch 27/300, Loss: 1.5540, Accuracy: 0.7126\n",
      "Epoch 28/300, Loss: 1.3951, Accuracy: 0.7207\n",
      "Epoch 29/300, Loss: 1.3334, Accuracy: 0.7349\n",
      "Epoch 30/300, Loss: 1.3738, Accuracy: 0.7491\n",
      "Epoch 31/300, Loss: 1.3048, Accuracy: 0.7547\n",
      "Epoch 32/300, Loss: 1.2128, Accuracy: 0.7624\n",
      "Epoch 33/300, Loss: 1.2076, Accuracy: 0.7755\n",
      "Epoch 34/300, Loss: 1.1079, Accuracy: 0.7873\n",
      "Epoch 35/300, Loss: 1.0791, Accuracy: 0.7969\n",
      "Epoch 36/300, Loss: 1.0357, Accuracy: 0.8089\n",
      "Epoch 37/300, Loss: 0.9445, Accuracy: 0.8210\n",
      "Epoch 38/300, Loss: 0.9246, Accuracy: 0.8334\n",
      "Epoch 39/300, Loss: 0.8839, Accuracy: 0.8429\n",
      "Epoch 40/300, Loss: 0.8433, Accuracy: 0.8499\n",
      "Epoch 41/300, Loss: 0.7943, Accuracy: 0.8645\n",
      "Epoch 42/300, Loss: 0.7588, Accuracy: 0.8747\n",
      "Epoch 43/300, Loss: 0.7155, Accuracy: 0.8859\n",
      "Epoch 44/300, Loss: 0.6560, Accuracy: 0.8943\n",
      "Epoch 45/300, Loss: 0.6290, Accuracy: 0.9035\n",
      "Epoch 46/300, Loss: 0.5723, Accuracy: 0.9117\n",
      "Epoch 47/300, Loss: 0.5466, Accuracy: 0.9224\n",
      "Epoch 48/300, Loss: 0.5029, Accuracy: 0.9307\n",
      "Epoch 49/300, Loss: 0.4799, Accuracy: 0.9388\n",
      "Epoch 50/300, Loss: 0.4495, Accuracy: 0.9423\n",
      "Epoch 51/300, Loss: 0.4300, Accuracy: 0.9501\n",
      "Epoch 52/300, Loss: 0.3884, Accuracy: 0.9561\n",
      "Epoch 53/300, Loss: 0.3659, Accuracy: 0.9610\n",
      "Epoch 54/300, Loss: 0.3477, Accuracy: 0.9658\n",
      "Epoch 55/300, Loss: 0.3129, Accuracy: 0.9687\n",
      "Epoch 56/300, Loss: 0.2964, Accuracy: 0.9741\n",
      "Epoch 57/300, Loss: 0.2856, Accuracy: 0.9767\n",
      "Epoch 58/300, Loss: 0.2569, Accuracy: 0.9801\n",
      "Epoch 59/300, Loss: 0.2370, Accuracy: 0.9827\n",
      "Epoch 60/300, Loss: 0.2270, Accuracy: 0.9839\n",
      "Epoch 61/300, Loss: 0.2073, Accuracy: 0.9846\n",
      "Epoch 62/300, Loss: 0.1901, Accuracy: 0.9863\n",
      "Epoch 63/300, Loss: 0.1816, Accuracy: 0.9879\n",
      "Epoch 64/300, Loss: 0.1756, Accuracy: 0.9876\n",
      "Epoch 65/300, Loss: 0.1641, Accuracy: 0.9883\n",
      "Epoch 66/300, Loss: 0.1469, Accuracy: 0.9901\n",
      "Epoch 67/300, Loss: 0.1472, Accuracy: 0.9898\n",
      "Epoch 68/300, Loss: 0.1319, Accuracy: 0.9906\n",
      "Epoch 69/300, Loss: 0.1299, Accuracy: 0.9900\n",
      "Epoch 70/300, Loss: 0.1196, Accuracy: 0.9905\n",
      "Epoch 71/300, Loss: 0.1113, Accuracy: 0.9913\n",
      "Epoch 72/300, Loss: 0.1080, Accuracy: 0.9912\n",
      "Epoch 73/300, Loss: 0.1036, Accuracy: 0.9917\n",
      "Epoch 74/300, Loss: 0.0957, Accuracy: 0.9918\n",
      "Epoch 75/300, Loss: 0.0937, Accuracy: 0.9917\n",
      "Epoch 76/300, Loss: 0.0892, Accuracy: 0.9920\n",
      "Epoch 77/300, Loss: 0.0873, Accuracy: 0.9919\n",
      "Epoch 78/300, Loss: 0.0842, Accuracy: 0.9920\n",
      "Epoch 79/300, Loss: 0.0824, Accuracy: 0.9919\n",
      "Epoch 80/300, Loss: 0.0829, Accuracy: 0.9913\n",
      "Epoch 81/300, Loss: 0.0761, Accuracy: 0.9920\n",
      "Epoch 82/300, Loss: 0.0747, Accuracy: 0.9919\n",
      "Epoch 83/300, Loss: 0.0689, Accuracy: 0.9926\n",
      "Epoch 84/300, Loss: 0.0732, Accuracy: 0.9916\n",
      "Epoch 85/300, Loss: 0.0667, Accuracy: 0.9922\n",
      "Epoch 86/300, Loss: 0.0656, Accuracy: 0.9925\n",
      "Epoch 87/300, Loss: 0.0660, Accuracy: 0.9920\n",
      "Epoch 88/300, Loss: 0.0747, Accuracy: 0.9907\n",
      "Epoch 89/300, Loss: 0.0656, Accuracy: 0.9920\n",
      "Epoch 90/300, Loss: 0.0611, Accuracy: 0.9919\n",
      "Epoch 91/300, Loss: 0.0601, Accuracy: 0.9922\n",
      "Epoch 92/300, Loss: 0.0575, Accuracy: 0.9923\n",
      "Epoch 93/300, Loss: 0.0559, Accuracy: 0.9922\n",
      "Epoch 94/300, Loss: 0.0521, Accuracy: 0.9926\n",
      "Epoch 95/300, Loss: 0.0534, Accuracy: 0.9919\n",
      "Epoch 96/300, Loss: 0.0510, Accuracy: 0.9923\n",
      "Epoch 97/300, Loss: 0.0499, Accuracy: 0.9924\n",
      "Epoch 98/300, Loss: 0.0487, Accuracy: 0.9925\n",
      "Epoch 99/300, Loss: 0.0483, Accuracy: 0.9923\n",
      "Epoch 100/300, Loss: 0.0459, Accuracy: 0.9925\n",
      "Epoch 101/300, Loss: 0.0441, Accuracy: 0.9929\n",
      "Epoch 102/300, Loss: 0.0432, Accuracy: 0.9927\n",
      "Epoch 103/300, Loss: 0.0427, Accuracy: 0.9926\n",
      "Epoch 104/300, Loss: 0.0409, Accuracy: 0.9923\n",
      "Epoch 105/300, Loss: 0.0404, Accuracy: 0.9927\n",
      "Epoch 106/300, Loss: 0.0402, Accuracy: 0.9926\n",
      "Epoch 107/300, Loss: 0.0408, Accuracy: 0.9923\n",
      "Epoch 108/300, Loss: 0.0390, Accuracy: 0.9927\n",
      "Epoch 109/300, Loss: 0.0374, Accuracy: 0.9927\n",
      "Epoch 110/300, Loss: 0.0362, Accuracy: 0.9928\n",
      "Epoch 111/300, Loss: 0.0365, Accuracy: 0.9925\n",
      "Epoch 112/300, Loss: 0.0352, Accuracy: 0.9928\n",
      "Epoch 113/300, Loss: 0.0349, Accuracy: 0.9927\n",
      "Epoch 114/300, Loss: 0.0354, Accuracy: 0.9930\n",
      "Epoch 115/300, Loss: 0.0385, Accuracy: 0.9924\n",
      "Epoch 116/300, Loss: 0.0369, Accuracy: 0.9926\n",
      "Epoch 117/300, Loss: 0.0347, Accuracy: 0.9927\n",
      "Epoch 118/300, Loss: 0.0360, Accuracy: 0.9925\n",
      "Epoch 119/300, Loss: 0.0460, Accuracy: 0.9915\n",
      "Epoch 120/300, Loss: 0.0481, Accuracy: 0.9910\n",
      "Epoch 121/300, Loss: 0.0432, Accuracy: 0.9917\n",
      "Epoch 122/300, Loss: 0.0368, Accuracy: 0.9924\n",
      "Epoch 123/300, Loss: 0.0352, Accuracy: 0.9926\n",
      "Epoch 124/300, Loss: 0.0334, Accuracy: 0.9926\n",
      "Epoch 125/300, Loss: 0.0333, Accuracy: 0.9926\n",
      "Epoch 126/300, Loss: 0.0316, Accuracy: 0.9925\n",
      "Epoch 127/300, Loss: 0.0322, Accuracy: 0.9924\n",
      "Epoch 128/300, Loss: 0.0306, Accuracy: 0.9923\n",
      "Epoch 129/300, Loss: 0.0294, Accuracy: 0.9928\n",
      "Epoch 130/300, Loss: 0.0293, Accuracy: 0.9926\n",
      "Epoch 131/300, Loss: 0.0311, Accuracy: 0.9928\n",
      "Epoch 132/300, Loss: 0.0353, Accuracy: 0.9925\n",
      "Epoch 133/300, Loss: 0.0376, Accuracy: 0.9917\n",
      "Epoch 134/300, Loss: 0.0357, Accuracy: 0.9922\n",
      "Epoch 135/300, Loss: 0.0353, Accuracy: 0.9922\n",
      "Epoch 136/300, Loss: 0.0332, Accuracy: 0.9925\n",
      "Epoch 137/300, Loss: 0.0316, Accuracy: 0.9922\n",
      "Epoch 138/300, Loss: 0.0317, Accuracy: 0.9927\n",
      "Epoch 139/300, Loss: 0.0309, Accuracy: 0.9924\n",
      "Epoch 140/300, Loss: 0.0289, Accuracy: 0.9927\n",
      "Epoch 141/300, Loss: 0.0287, Accuracy: 0.9926\n",
      "Epoch 142/300, Loss: 0.0284, Accuracy: 0.9926\n",
      "Epoch 143/300, Loss: 0.0289, Accuracy: 0.9926\n",
      "Epoch 144/300, Loss: 0.0304, Accuracy: 0.9923\n",
      "Epoch 145/300, Loss: 0.0284, Accuracy: 0.9927\n",
      "Epoch 146/300, Loss: 0.0298, Accuracy: 0.9928\n",
      "Epoch 147/300, Loss: 0.0303, Accuracy: 0.9924\n",
      "Epoch 148/300, Loss: 0.0294, Accuracy: 0.9925\n",
      "Epoch 149/300, Loss: 0.0284, Accuracy: 0.9923\n",
      "Epoch 150/300, Loss: 0.0279, Accuracy: 0.9928\n",
      "Epoch 151/300, Loss: 0.0273, Accuracy: 0.9926\n",
      "Epoch 152/300, Loss: 0.0269, Accuracy: 0.9925\n",
      "Epoch 153/300, Loss: 0.0261, Accuracy: 0.9925\n",
      "Epoch 154/300, Loss: 0.0272, Accuracy: 0.9926\n",
      "Epoch 155/300, Loss: 0.0268, Accuracy: 0.9926\n",
      "Epoch 156/300, Loss: 0.0267, Accuracy: 0.9927\n",
      "Epoch 157/300, Loss: 0.0262, Accuracy: 0.9925\n",
      "Epoch 158/300, Loss: 0.0251, Accuracy: 0.9925\n",
      "Epoch 159/300, Loss: 0.0245, Accuracy: 0.9926\n",
      "Epoch 160/300, Loss: 0.0235, Accuracy: 0.9927\n",
      "Epoch 161/300, Loss: 0.0249, Accuracy: 0.9927\n",
      "Epoch 162/300, Loss: 0.0249, Accuracy: 0.9929\n",
      "Epoch 163/300, Loss: 0.0250, Accuracy: 0.9927\n",
      "Epoch 164/300, Loss: 0.0262, Accuracy: 0.9927\n",
      "Epoch 165/300, Loss: 0.0273, Accuracy: 0.9926\n",
      "Epoch 166/300, Loss: 0.0266, Accuracy: 0.9926\n",
      "Epoch 167/300, Loss: 0.0268, Accuracy: 0.9925\n",
      "Epoch 168/300, Loss: 0.0288, Accuracy: 0.9923\n",
      "Epoch 169/300, Loss: 0.0330, Accuracy: 0.9917\n",
      "Epoch 170/300, Loss: 0.0272, Accuracy: 0.9924\n",
      "Epoch 171/300, Loss: 0.0252, Accuracy: 0.9924\n",
      "Epoch 172/300, Loss: 0.0248, Accuracy: 0.9926\n",
      "Epoch 173/300, Loss: 0.0244, Accuracy: 0.9922\n",
      "Epoch 174/300, Loss: 0.0245, Accuracy: 0.9927\n",
      "Epoch 175/300, Loss: 0.0278, Accuracy: 0.9923\n",
      "Epoch 176/300, Loss: 0.0259, Accuracy: 0.9926\n",
      "Epoch 177/300, Loss: 0.0324, Accuracy: 0.9925\n",
      "Epoch 178/300, Loss: 0.0258, Accuracy: 0.9923\n",
      "Epoch 179/300, Loss: 0.0233, Accuracy: 0.9930\n",
      "Epoch 180/300, Loss: 0.0223, Accuracy: 0.9927\n",
      "Epoch 181/300, Loss: 0.0222, Accuracy: 0.9926\n",
      "Epoch 182/300, Loss: 0.0223, Accuracy: 0.9929\n",
      "Epoch 183/300, Loss: 0.0221, Accuracy: 0.9928\n",
      "Epoch 184/300, Loss: 0.0242, Accuracy: 0.9925\n",
      "Epoch 185/300, Loss: 0.0291, Accuracy: 0.9920\n",
      "Epoch 186/300, Loss: 0.0275, Accuracy: 0.9924\n",
      "Epoch 187/300, Loss: 0.0268, Accuracy: 0.9922\n",
      "Epoch 188/300, Loss: 0.0262, Accuracy: 0.9926\n",
      "Epoch 189/300, Loss: 0.0270, Accuracy: 0.9920\n",
      "Epoch 190/300, Loss: 0.0271, Accuracy: 0.9924\n",
      "Epoch 191/300, Loss: 0.0274, Accuracy: 0.9922\n",
      "Epoch 192/300, Loss: 0.0256, Accuracy: 0.9928\n",
      "Epoch 193/300, Loss: 0.0272, Accuracy: 0.9924\n",
      "Epoch 194/300, Loss: 0.0290, Accuracy: 0.9919\n",
      "Epoch 195/300, Loss: 0.0268, Accuracy: 0.9924\n",
      "Epoch 196/300, Loss: 0.0348, Accuracy: 0.9905\n",
      "Epoch 197/300, Loss: 0.0295, Accuracy: 0.9920\n",
      "Epoch 198/300, Loss: 0.0288, Accuracy: 0.9921\n",
      "Epoch 199/300, Loss: 0.0303, Accuracy: 0.9920\n",
      "Epoch 200/300, Loss: 0.0316, Accuracy: 0.9919\n",
      "Epoch 201/300, Loss: 0.0322, Accuracy: 0.9913\n",
      "Epoch 202/300, Loss: 0.0400, Accuracy: 0.9899\n",
      "Epoch 203/300, Loss: 0.0355, Accuracy: 0.9910\n",
      "Epoch 204/300, Loss: 0.0298, Accuracy: 0.9919\n",
      "Epoch 205/300, Loss: 0.0260, Accuracy: 0.9918\n",
      "Epoch 206/300, Loss: 0.0294, Accuracy: 0.9922\n",
      "Epoch 207/300, Loss: 0.0561, Accuracy: 0.9876\n",
      "Epoch 208/300, Loss: 0.0363, Accuracy: 0.9908\n",
      "Epoch 209/300, Loss: 0.0338, Accuracy: 0.9913\n",
      "Epoch 210/300, Loss: 0.0277, Accuracy: 0.9922\n",
      "Epoch 211/300, Loss: 0.0239, Accuracy: 0.9927\n",
      "Epoch 212/300, Loss: 0.0244, Accuracy: 0.9926\n",
      "Epoch 213/300, Loss: 0.0249, Accuracy: 0.9925\n",
      "Epoch 214/300, Loss: 0.0339, Accuracy: 0.9918\n",
      "Epoch 215/300, Loss: 0.0348, Accuracy: 0.9918\n",
      "Epoch 216/300, Loss: 0.0308, Accuracy: 0.9921\n",
      "Epoch 217/300, Loss: 0.0256, Accuracy: 0.9925\n",
      "Epoch 218/300, Loss: 0.0228, Accuracy: 0.9926\n",
      "Epoch 219/300, Loss: 0.0220, Accuracy: 0.9926\n",
      "Epoch 220/300, Loss: 0.0227, Accuracy: 0.9929\n",
      "Epoch 221/300, Loss: 0.0237, Accuracy: 0.9925\n",
      "Epoch 222/300, Loss: 0.0230, Accuracy: 0.9925\n",
      "Epoch 223/300, Loss: 0.0222, Accuracy: 0.9930\n",
      "Epoch 224/300, Loss: 0.0204, Accuracy: 0.9928\n",
      "Epoch 225/300, Loss: 0.0201, Accuracy: 0.9928\n",
      "Epoch 226/300, Loss: 0.0214, Accuracy: 0.9928\n",
      "Epoch 227/300, Loss: 0.0217, Accuracy: 0.9927\n",
      "Epoch 228/300, Loss: 0.0198, Accuracy: 0.9928\n",
      "Epoch 229/300, Loss: 0.0211, Accuracy: 0.9929\n",
      "Epoch 230/300, Loss: 0.0207, Accuracy: 0.9928\n",
      "Epoch 231/300, Loss: 0.0214, Accuracy: 0.9930\n",
      "Epoch 232/300, Loss: 0.0208, Accuracy: 0.9929\n",
      "Epoch 233/300, Loss: 0.0194, Accuracy: 0.9931\n",
      "Epoch 234/300, Loss: 0.0203, Accuracy: 0.9927\n",
      "Epoch 235/300, Loss: 0.0209, Accuracy: 0.9928\n",
      "Epoch 236/300, Loss: 0.0234, Accuracy: 0.9924\n",
      "Epoch 237/300, Loss: 0.0232, Accuracy: 0.9923\n",
      "Epoch 238/300, Loss: 0.0211, Accuracy: 0.9924\n",
      "Epoch 239/300, Loss: 0.0218, Accuracy: 0.9924\n",
      "Epoch 240/300, Loss: 0.0195, Accuracy: 0.9928\n",
      "Epoch 241/300, Loss: 0.0198, Accuracy: 0.9928\n",
      "Epoch 242/300, Loss: 0.0223, Accuracy: 0.9925\n",
      "Epoch 243/300, Loss: 0.0216, Accuracy: 0.9929\n",
      "Epoch 244/300, Loss: 0.0200, Accuracy: 0.9929\n",
      "Epoch 245/300, Loss: 0.0192, Accuracy: 0.9925\n",
      "Epoch 246/300, Loss: 0.0196, Accuracy: 0.9926\n",
      "Epoch 247/300, Loss: 0.0185, Accuracy: 0.9929\n",
      "Epoch 248/300, Loss: 0.0185, Accuracy: 0.9925\n",
      "Epoch 249/300, Loss: 0.0189, Accuracy: 0.9926\n",
      "Epoch 250/300, Loss: 0.0184, Accuracy: 0.9929\n",
      "Epoch 251/300, Loss: 0.0186, Accuracy: 0.9930\n",
      "Epoch 252/300, Loss: 0.0204, Accuracy: 0.9926\n",
      "Epoch 253/300, Loss: 0.0210, Accuracy: 0.9925\n",
      "Epoch 254/300, Loss: 0.0226, Accuracy: 0.9929\n",
      "Epoch 255/300, Loss: 0.0217, Accuracy: 0.9924\n",
      "Epoch 256/300, Loss: 0.0209, Accuracy: 0.9927\n",
      "Epoch 257/300, Loss: 0.0214, Accuracy: 0.9928\n",
      "Epoch 258/300, Loss: 0.0216, Accuracy: 0.9928\n",
      "Epoch 259/300, Loss: 0.0215, Accuracy: 0.9929\n",
      "Epoch 260/300, Loss: 0.0201, Accuracy: 0.9926\n",
      "Epoch 261/300, Loss: 0.0219, Accuracy: 0.9924\n",
      "Epoch 262/300, Loss: 0.0264, Accuracy: 0.9916\n",
      "Epoch 263/300, Loss: 0.0209, Accuracy: 0.9925\n",
      "Epoch 264/300, Loss: 0.0193, Accuracy: 0.9929\n",
      "Epoch 265/300, Loss: 0.0197, Accuracy: 0.9929\n",
      "Epoch 266/300, Loss: 0.0202, Accuracy: 0.9928\n",
      "Epoch 267/300, Loss: 0.0209, Accuracy: 0.9927\n",
      "Epoch 268/300, Loss: 0.0241, Accuracy: 0.9924\n",
      "Epoch 269/300, Loss: 0.0215, Accuracy: 0.9926\n",
      "Epoch 270/300, Loss: 0.0194, Accuracy: 0.9926\n",
      "Epoch 271/300, Loss: 0.0185, Accuracy: 0.9927\n",
      "Epoch 272/300, Loss: 0.0182, Accuracy: 0.9929\n",
      "Epoch 273/300, Loss: 0.0208, Accuracy: 0.9923\n",
      "Epoch 274/300, Loss: 0.0230, Accuracy: 0.9925\n",
      "Epoch 275/300, Loss: 0.0207, Accuracy: 0.9925\n",
      "Epoch 276/300, Loss: 0.0202, Accuracy: 0.9925\n",
      "Epoch 277/300, Loss: 0.0184, Accuracy: 0.9925\n",
      "Epoch 278/300, Loss: 0.0191, Accuracy: 0.9926\n",
      "Epoch 279/300, Loss: 0.0198, Accuracy: 0.9925\n",
      "Epoch 280/300, Loss: 0.0190, Accuracy: 0.9929\n",
      "Epoch 281/300, Loss: 0.0192, Accuracy: 0.9925\n",
      "Epoch 282/300, Loss: 0.0195, Accuracy: 0.9928\n",
      "Epoch 283/300, Loss: 0.0191, Accuracy: 0.9929\n",
      "Epoch 284/300, Loss: 0.0190, Accuracy: 0.9927\n",
      "Epoch 285/300, Loss: 0.0203, Accuracy: 0.9924\n",
      "Epoch 286/300, Loss: 0.0201, Accuracy: 0.9927\n",
      "Epoch 287/300, Loss: 0.0190, Accuracy: 0.9927\n",
      "Epoch 288/300, Loss: 0.0233, Accuracy: 0.9925\n",
      "Epoch 289/300, Loss: 0.0264, Accuracy: 0.9923\n",
      "Epoch 290/300, Loss: 0.0274, Accuracy: 0.9914\n",
      "Epoch 291/300, Loss: 0.0238, Accuracy: 0.9922\n",
      "Epoch 292/300, Loss: 0.0320, Accuracy: 0.9907\n",
      "Epoch 293/300, Loss: 0.0296, Accuracy: 0.9909\n",
      "Epoch 294/300, Loss: 0.0259, Accuracy: 0.9919\n",
      "Epoch 295/300, Loss: 0.0262, Accuracy: 0.9916\n",
      "Epoch 296/300, Loss: 0.0235, Accuracy: 0.9923\n",
      "Epoch 297/300, Loss: 0.0218, Accuracy: 0.9923\n",
      "Epoch 298/300, Loss: 0.0224, Accuracy: 0.9921\n",
      "Epoch 299/300, Loss: 0.0210, Accuracy: 0.9925\n",
      "Epoch 300/300, Loss: 0.0211, Accuracy: 0.9924\n"
     ]
    }
   ],
   "source": [
    "# Training Loop with Loss and Accuracy\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    for questions_batch, answers_batch in dataloader:\n",
    "        questions_batch = questions_batch.to(device)\n",
    "        decoder_input = answers_batch[:, :-1].to(device)  # Input for decoder\n",
    "        target = answers_batch[:, 1:].to(device)  # Target for training\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(questions_batch, decoder_input)\n",
    "        loss = criterion(output.reshape(-1, VOCAB_SIZE), target.reshape(-1))\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        predicted_tokens = torch.argmax(output, dim=-1)\n",
    "        correct_tokens = (predicted_tokens == target).sum().item()\n",
    "        total_accuracy += correct_tokens\n",
    "        total_tokens += target.numel()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    epoch_loss = total_loss / len(dataloader)\n",
    "    epoch_accuracy = total_accuracy / total_tokens\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9b389d-7ea7-419f-ae58-98dff048e88f",
   "metadata": {},
   "source": [
    "### Export the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "62ea317a-2071-404d-ac52-736e81aa201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model/transformer_chatbot_gpu_deco_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4655b734-09b0-49bc-a150-24fdeb13b25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model/tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1881f4d7-7754-4da2-b54a-d900b2cb878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports specific to the trading strategy functionality\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def livermore_backtest(stock_symbol='NVDA', start_date_str='2020-01-01', end_date_str='2024-12-31'):\n",
    "    \"\"\"\n",
    "    Runs a Livermore-inspired backtest on a given stock from start_date to end_date.\n",
    "    Returns a summary string and a matplotlib figure showing the cumulative returns.\n",
    "    \"\"\"\n",
    "    # Convert date strings to datetime objects\n",
    "    start_date = pd.to_datetime(start_date_str)\n",
    "    end_date = pd.to_datetime(end_date_str)\n",
    "    \n",
    "    # Download historical data for the stock\n",
    "    stock_data = yf.download(stock_symbol, start=start_date, end=end_date)\n",
    "    \n",
    "    # Check if the downloaded data has MultiIndex columns\n",
    "    if isinstance(stock_data.columns, pd.MultiIndex):\n",
    "        try:\n",
    "            # Some versions may use 'Ticker' as the level name\n",
    "            df = stock_data.xs(stock_symbol, axis=1, level='Ticker')\n",
    "        except Exception:\n",
    "            # Otherwise, try with the first level\n",
    "            df = stock_data.xs(stock_symbol, axis=1, level=0)\n",
    "    else:\n",
    "        df = stock_data.copy()\n",
    "        \n",
    "    # Now, df should have simple columns like 'Open', 'High', 'Low', 'Close', etc.\n",
    "    # Calculate moving averages\n",
    "    df['50MA'] = df['Close'].rolling(window=50).mean()\n",
    "    df['200MA'] = df['Close'].rolling(window=200).mean()\n",
    "    \n",
    "    # Define breakout levels (previous 20-day high/low)\n",
    "    df['20High'] = df['Close'].rolling(window=20).max()\n",
    "    df['20Low'] = df['Close'].rolling(window=20).min()\n",
    "    \n",
    "    # Create positions: buy when price breaks above yesterday's 20-day high and is above both moving averages; sell otherwise\n",
    "    df['Position'] = 0\n",
    "    df.loc[\n",
    "        (df['Close'] > df['20High'].shift(1)) &\n",
    "        (df['Close'] > df['50MA']) &\n",
    "        (df['Close'] > df['200MA']),\n",
    "        'Position'\n",
    "    ] = 1\n",
    "    df.loc[df['Close'] < df['20Low'].shift(1), 'Position'] = 0\n",
    "    df['Position'] = df['Position'].ffill().fillna(0)\n",
    "    \n",
    "    # Compute returns for buy-and-hold versus strategy\n",
    "    df['Buy-and-Hold Return'] = df['Close'].pct_change()\n",
    "    df['Strategy Return'] = df['Buy-and-Hold Return'] * df['Position']\n",
    "    \n",
    "    # Compute cumulative returns\n",
    "    buy_and_hold_cum = df['Buy-and-Hold Return'].cumsum()\n",
    "    strategy_cum = df['Strategy Return'].cumsum()\n",
    "    \n",
    "    # Plot the cumulative returns\n",
    "    fig, ax = plt.subplots(figsize=(12,6))\n",
    "    ax.plot(buy_and_hold_cum, label='Buy-and-Hold Return')\n",
    "    ax.plot(strategy_cum, label='Strategy Return')\n",
    "    ax.set_title(f\"{stock_symbol}: Livermore-Inspired Trading Strategy vs Buy-and-Hold\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Cumulative Return\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    plt.close(fig)  # close figure to prevent auto display in non-interactive environments\n",
    "    \n",
    "    # Create a summary message\n",
    "    summary = f\"**{stock_symbol} Backtest Summary ({start_date_str} to {end_date_str})**\\n\"\n",
    "    summary += f\"Final Buy-and-Hold Return: {buy_and_hold_cum.iloc[-1]:.2%}\\n\"\n",
    "    summary += f\"Final Strategy Return: {strategy_cum.iloc[-1]:.2%}\\n\"\n",
    "    return summary, fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1da813e4-407b-461e-869d-6f6ab33ffc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_livermore_strategy(response, question):\n",
    "    \"\"\"\n",
    "    Examines the user question for trading-related keywords. If detected,\n",
    "    runs the Livermore backtest and appends the summary to the base response.\n",
    "    \"\"\"\n",
    "    keywords = ['backtest', 'trading', 'stock', 'chart', 'performance']\n",
    "    if any(keyword in question.lower() for keyword in keywords):\n",
    "        # You could also attempt to parse out custom parameters from the question.\n",
    "        # For now, we use default values.\n",
    "        summary, fig = livermore_backtest()\n",
    "        # Append the backtest summary to the generated answer\n",
    "        response += \"\\n\\n\" + summary\n",
    "        # For notebooks: display the plot\n",
    "        try:\n",
    "            from IPython.display import display\n",
    "            display(fig)\n",
    "        except ImportError:\n",
    "            pass  # In a non-notebook environment, you might save the figure instead\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6e70649b-0654-49a0-8d73-d444d80e3447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_response_with_strategy(question, tokenizer, model, max_len=40):\n",
    "    \"\"\"\n",
    "    Generates a chatbot response using the transformer model and then applies\n",
    "    Livermore-inspired modifications if the question is trading-related.\n",
    "    \"\"\"\n",
    "    base_response = chat_response(question, tokenizer, model, max_len)\n",
    "    final_response = apply_livermore_strategy(base_response, question)\n",
    "    return final_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7c7476-7b2d-4e0c-892c-ae0dbfda7c01",
   "metadata": {},
   "source": [
    "### Load and Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b3a732d0-3507-426d-8e02-ef7e95b2e0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Livermore: Hello. I'm always watching the tape. What brings you to the market today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Livermore: Hello there. Shall we talk tape or tactics?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Livermore: Hello there. Shall we talk tape or tactics?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  How are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Livermore: I'm steady—like a trader should be. Emotions must never swing more than the market.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  How are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Livermore: I'm steady—like a trader should be. Emotions must never swing more than the market.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Livermore: Hello. I'm always watching the tape. What brings you to the market today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  How are you doing?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Livermore: Analyzing trends and waiting for the right setup. Patience is a position too.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Who are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Livermore: I'm always observing the market's mood. Today, it seems to be showing signs of accumulation.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  What's your name?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Livermore: I’m Jesse Livermore. Some called me the Boy Plunger. I just followed the tape.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  What are your principles?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Livermore: My trading principles are forged through decades of wins and losses. First and foremost, I cut my losses quickly—there’s no honor in holding a losing position. I let my winners run, never interfere with a stock that’s working.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  What is boolish?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Livermore: A bullish market or stock shows strength—higher highs, strong demand, and volume confirming momentum. It means the path of least resistance is upward. In such times, I look to go long.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting chatbot. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Load the Trained Model\n",
    "model.load_state_dict(torch.load(\"model/transformer_chatbot_gpu_deco_1.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Chat Function\n",
    "def chat_response(question, tokenizer, model, max_len=40):\n",
    "    model.eval()\n",
    "    question_seq = tokenizer.texts_to_sequences([question])[0]\n",
    "    question_seq = [1] + question_seq[:max_len - 2] + [2]  # Add <start> and <end> tokens\n",
    "    question_seq = question_seq + [0] * (max_len - len(question_seq))  # Pad to max_len\n",
    "    question_tensor = torch.tensor([question_seq]).to(device)\n",
    "\n",
    "    decoder_input = torch.tensor([[1]]).to(device)  # Start token\n",
    "    response = []\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        with torch.no_grad():\n",
    "            output = model(question_tensor, decoder_input)\n",
    "        predicted_id = torch.argmax(output[:, -1, :], dim=-1).item()\n",
    "        if predicted_id == 2:  # End token\n",
    "            break\n",
    "        response.append(predicted_id)\n",
    "        decoder_input = torch.cat([decoder_input, torch.tensor([[predicted_id]]).to(device)], dim=-1)\n",
    "\n",
    "    return tokenizer.sequences_to_texts([response])[0].replace(\"<start>\", \"\").replace(\"<end>\", \"\").strip()\n",
    "\n",
    "# Interactive Chat Loop\n",
    "# while True:\n",
    "#     user_input = input(\"You: \")\n",
    "#     if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "#         print(\"Exiting chatbot. Goodbye!\")\n",
    "#         break\n",
    "#     bot_response = chat_response(user_input, tokenizer, model)\n",
    "#     print(f\"Bot: {bot_response}\")\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Exiting chatbot. Goodbye!\")\n",
    "        break\n",
    "    # Generate a base response and then adjust it with Livermore logic\n",
    "    bot_response = chat_response_with_strategy(user_input, tokenizer, model)\n",
    "    print(f\"Livermore: {bot_response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576c75c2-47dd-4313-b4ab-3173781bf9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
